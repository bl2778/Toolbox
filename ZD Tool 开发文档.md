1. åŠŸèƒ½èŒƒå›´ï¼ˆScopeï¼‰
è¾“å…¥ï¼šç”¨æˆ·ä¸Šä¼ çš„ .pptx
å¤„ç†ï¼š
1.	è§£æ PPT â†’ ç»“æ„åŒ– JSON
2.	æŒ‰è§„åˆ™åˆ‡å—ï¼ˆå¿«é€Ÿ/ä»”ç»†ä¸¤ç§æ¨¡å¼ï¼‰ï¼Œä»¥é¡µä¸ºæœ€å°é¢—ç²’å¹¶æ”¯æŒè·¨å— 1 é¡µé‡å 
3.	ä»¥é¢„ç½® Promptæ‹¼æ¥æ¯å—æ–‡æœ¬ â†’ å¹¶å‘è°ƒç”¨ LLM
4.	å½’å¹¶æ‰€æœ‰å—çš„è¿”å›è¡¨æ ¼ï¼ŒæŒ‰é¡µé¢é¡ºåºè¾“å‡º
5.	æ˜¾ç¤ºè¿›åº¦ï¼ˆè§£æ â†’ å‘é€ Prompt â†’ AI æ€è€ƒä¸­ â†’ æ•´ç†ç»“æœï¼‰
6.	ç¨³å¥æ€§ï¼šé»˜è®¤ä¸è‡ªåŠ¨é‡è¯•ï¼›å…è®¸ç”¨æˆ·å¯¹å¤±è´¥å—å•ç‹¬é‡è·‘å¹¶åˆ·æ–°ç»“æœè¾“å‡ºï¼šæ¯é¡µä¸€è¡Œçš„ä¸‰åˆ—è¡¨æ ¼ï¼ˆæ‹¼å†™/è¯­æ³•-è¡¨è¿°/é€»è¾‘ï¼‰ï¼Œæ”¯æŒå¯¼å‡º CSV/Excel
ä¸åšï¼šä¿®æ­£æ–‡æ¡ˆæœ¬èº«ï¼›å¯¹éæ–‡æœ¬å¯¹è±¡ï¼ˆå›¾ç‰‡/å›¾è¡¨æ•°æ®ï¼‰åš OCR æˆ–æ•°å€¼æ ¡éªŒï¼ˆåç»­å¯æ‰©å±•ï¼‰ã€‚
________________________________________
2. ç«¯åˆ°ç«¯æµç¨‹ï¼ˆE2Eï¼‰
1.	ä¸Šä¼ ï¼šå‰ç«¯æ¥æ”¶ .pptx â†’ åç«¯å­˜å‚¨ä¸´æ—¶å¯¹è±¡ï¼ˆåŠ å¯†ï¼Œæ—¶æ•ˆ 24hï¼‰ã€‚
2.	è§£æï¼šè§ç¬¬ä¸‰èŠ‚
3.	åˆ‡å—ï¼ˆè§ç¬¬ 4 èŠ‚ï¼‰ï¼šæŒ‰æ¨¡å¼å°†å¤šé¡µèšåˆä¸ºè‹¥å¹²å—ï¼Œä¸æ‹†é¡µï¼Œå¹¶åœ¨å—é—´é‡å  1 é¡µã€‚
4.	Prompt æ‹¼è£…ï¼šå¯¹æ¯å—æ„é€ å›ºå®šå‰è¨€ + slides JSONï¼Œå¹¶è¿½åŠ è¾“å‡ºæ ¼å¼çº¦æŸï¼ˆåªå…è®¸å¼ºåŒ–â€œè¿”å›ç»“æ„â€ï¼Œä¸æ”¹ä»»åŠ¡è¯­ä¹‰ï¼‰ã€‚
5.	å¹¶å‘æ‰§è¡Œï¼šæŒ‰å—å¹¶å‘è°ƒç”¨ LLMï¼ˆé™æµå¯é…ï¼‰ï¼Œæ”¶é›†æ¯å—çš„æ ‡å‡†åŒ–è¡¨æ ¼ç»“æœã€‚
6.	å½’å¹¶æ’åºï¼šä»¥ page_number ä¸ºä¸»é”®åˆå¹¶å¤šå—ç»“æœï¼ˆå¤„ç†é‡å é¡µå»é‡/åˆå¹¶ï¼‰ï¼Œç”Ÿæˆæœ€ç»ˆå…¨å†Œè¡¨ã€‚
7.	å±•ç¤ºä¸å¯¼å‡ºï¼šå‰ç«¯å±•ç¤ºå¯ç­›é€‰è¡¨æ ¼ï¼ˆæ”¯æŒæŒ‰é—®é¢˜ç±»å‹/æ˜¯å¦ä¸ºç©ºç­›é€‰ï¼‰ï¼Œå¹¶æä¾› CSV/XLSX å¯¼å‡ºã€‚
8.	å¤±è´¥é‡è·‘ï¼šæ ‡è®°å¤±è´¥å—ï¼Œå…è®¸å•å—é‡æå¹¶å¢é‡åˆ·æ–°æ±‡æ€»ã€‚
________________________________________
3. æ•°æ®æ¨¡å‹ï¼ˆå…³é”® Schemaï¼‰
3.1 è§£æåæ¯é¡µ JSON
{
  "slide_number": 1,
  "elements": "Market growth slows in FY25",
  "notes": "- US +2% YoY\\\\n- EU -1% YoY\\\\nNote: excludes divested unit"
}
 
3.2 åˆ‡å—ç»“æœ
{
  "chunk_id": "ck_0001",
  "mode": "fast|precise",
  "page_start": 1,
  "page_end": 8,
  "page_numbers": [1,2,3,4,5,6,7,8],
  "word_count": 5600
}
 
3.3 LLM è¯·æ±‚è½½è·ï¼ˆæ¯å—ï¼‰
{
  "system": "<å›ºå®šå‰è¨€ï¼šZD ä»»åŠ¡è¯´æ˜>",
  "user": {
    "slides": [
      {
        "page_number": 1,
        "tagline": "...",
        "body_other": "...",
        "speaker_notes": "Do not review"
      }
      // ...
    ],
    "format": "è¯·æŒ‰ä¸‹è¿°è¡¨æ ¼è¿”å›ï¼ˆè§ç¬¬ 5 èŠ‚æ ¼å¼çº¦æŸï¼‰"
  }
}
 
3.4 LLM æ ‡å‡†åŒ–è¿”å›ï¼ˆè§£æåå†…éƒ¨ç»“æ„ï¼‰
è™½ç„¶æ¨¡å‹äº§å‡ºä¸º Markdown è¡¨æ ¼ï¼ŒæœåŠ¡ç«¯éœ€å°†å…¶è§„èŒƒåŒ–ä¸º JSONä¾¿äºåˆå¹¶/å¯¼å‡ºã€‚
[
  {
    "page_number": 1,
    "spelling": ["recieve", "adress"],
    "grammar": ["Missing article before 'EU'", "Inconsistent tense"],
    "logic": ["â†” p 5: tagline contradicts EU decline"]
  }
]
 
3.5 è¿è¡ŒçŠ¶æ€ï¼ˆProgressï¼‰
{
  "job_id": "job_123",
  "status": "parsing|chunking|prompting|thinking|merging|done|error",
  "counts": {
    "chunks_total": 7,
    "chunks_sent": 7,
    "chunks_completed": 3,
    "chunks_failed": 1
  },
  "percent": 43
}
 
________________________________________
4. æ–‡æœ¬åˆ‡å—è§„åˆ™ï¼ˆå®ç°è¦ç‚¹ï¼‰
ä¸¤ç§æ¨¡å¼å‡ä»¥é¡µä¸ºå•ä½ï¼Œä¸æ‹†é¡µï¼Œè·¨å—é‡å  1 é¡µã€‚è¯æ•°ä»…ç»Ÿè®¡ tagline + body_otherï¼ˆè‹±æ–‡åœºæ™¯ï¼‰ã€‚
â€¢	æ–¹æ¡ˆ Aï½œå¿«é€Ÿ 
o	ç›®æ ‡è¯æ•°/æ‰¹ï¼š4,000â€“6,500
o	æ¯æ‰¹æœ€å¤§é¡µæ•°ï¼š10 é¡µ
o	é‡å é¡µæ•°ï¼š1 é¡µ
â€¢	æ–¹æ¡ˆ Bï½œä»”ç»† 
o	ç›®æ ‡è¯æ•°/æ‰¹ï¼š2,500â€“4,000
o	æ¯æ‰¹æœ€å¤§é¡µæ•°ï¼š5 é¡µ
o	é‡å é¡µæ•°ï¼š1 é¡µ
å®ç°å»ºè®®ï¼š
â€¢	é€é¡µç´¯åŠ è¯æ•°ï¼ˆsplit(/\\\\s+/) è¿‘ä¼¼ï¼‰ï¼Œè¾¾åˆ°ç›®æ ‡ä¸Šé™æˆ–é¡µæ•°ä¸Šé™å³åˆ‡å—ï¼›è‹¥ä¸‹é¡µåŠ å…¥åè¶…ä¸Šé™ä¸”å½“å‰å—ä¸ºç©ºï¼Œåˆ™å…è®¸å•é¡µè¶…é™ä¸€æ¬¡ä»¥é¿å…æ­»é”ã€‚
â€¢	ç”Ÿæˆå—åºåˆ—åï¼Œæ’å…¥é‡å ï¼šå— i çš„æœ€å 1 é¡µ = å— i+1 çš„ç¬¬ä¸€é¡µã€‚
â€¢	ä¸ºè·¨é¡µé€»è¾‘æ ¡éªŒä¿ç•™é‡å ï¼Œå»é‡ç­–ç•¥è§ç¬¬ 6 èŠ‚ã€‚
________________________________________
5. Prompt
å›ºå®šéƒ¨åˆ†ï¼ˆå·²æä¾›ï¼›ä¿æŒåŸæ–‡ï¼Œä¸æ”¹ä»»åŠ¡è¯­ä¹‰ï¼‰ï¼š
You are a McKinsey-style consultant performing a Zero-Defect (ZD) and logic review of an English-language PowerPoint deck that has been exported for you as easy-to-read JSON.
For every slide you will receive:
â€¢ page_number
â€¢ tagline â€“ headline text (highest priority)
â€¢ body_other â€“ body copy, bullets, call-outs, charts (second priority; ignore purely alphanumeric labels such as â€œA.â€ â€œI-1â€ that serve only as markers)
â€¢ speaker_notes â€“ presenter notes (do not review)
 
Tasks for each slide
Spelling mistakes â€“ typos, repeated letters, wrong homophones, etc.
Grammar / phrasing issues â€“ subjectâ€“verb agreement, tense, articles, punctuation, awkward wording, etc.
Logic inconsistencies
Within the slide: contradictions between the tagline and the body_other content, or internal logical gaps.
Across slides: contradictions or mis-alignments between this slideâ€™s tagline and earlier/later taglines. (Reference both page numbers when you spot one.)
Output format
Produce a three-column table where each row corresponds to one slide.
 
Slide Spelling mistakes Grammar / wording issues Logic inconsistencies
â€¢ Column 1 â€“ Comma-separated list of spelling mistakes for that slide, or â€œâ€”â€ if none.
â€¢ Column 2 â€“ Comma-separated list of grammar / wording issues, or â€œâ€”â€.
â€¢ Column 3 â€“
â€œâ€”â€ if the slide is logically sound.
Otherwise, a short description of the inconsistency.
For cross-slide issues, prefix with â€œâ†” p Xâ€ where X is the other slideâ€™s page_number (e.g., â€œâ†” p 5: tagline contradicts revenue trendâ€).
â€¢ Do NOT correct or rewrite the original content; only list the issues.
 
**Return a GitHub-Flavored Markdown table with columns: page_number | Spelling mistakes | Grammar / wording issues | Logic inconsistencies.
No explanations, no code fences.**
 
________________________________________
6. ç»“æœå½’å¹¶ä¸å»é‡
â€¢	ä¸»é”®ï¼špage_number
â€¢	é‡å é¡µåˆå¹¶ï¼šè‹¥åŒä¸€é¡µåœ¨ç›¸é‚»å—å‡å‡ºç°ï¼Œè¿›è¡Œé¡¹çº§å»é‡ï¼ˆå­—ç¬¦ä¸²å»é‡/åˆå¹¶ï¼‰ã€‚
â€¢	é¡ºåºï¼šæŒ‰ page_number å‡åºã€‚
â€¢	ç©ºå€¼æ ‡å‡†ï¼šä¸‰åˆ—å‡æ— é—®é¢˜æ—¶ä½¿ç”¨ â€”ã€‚
â€¢	å¯¼å‡ºï¼šCSV/XLSXï¼Œç¼–ç  UTF-8ï¼Œå­—æ®µåŒ…å«ï¼špage_number, spelling[], grammar[], logic[] ä¸ Markdown å±•ç¤ºç‰ˆå„ä¸€ä»½ã€‚
________________________________________
7. å¹¶å‘ä¸ç¨³å¥æ€§ï¼ˆRobustnessï¼‰
â€¢	å¹¶å‘åº¦ï¼šå¯é…ï¼ˆé»˜è®¤ max_concurrency = 5ï¼‰ï¼›é‡åˆ° 429/é™æµé‡‡ç”¨æŒ‡æ•°é€€é¿ + å•å—é‡è¯• 0 æ¬¡ï¼ˆé»˜è®¤ï¼‰ã€‚
â€¢	å¤±è´¥ç­–ç•¥ï¼šè®°å½•å¤±è´¥ chunk_id ä¸é”™è¯¯åŸå› ï¼›å‰ç«¯æä¾›â€œä»…é‡è·‘è¯¥å—â€æŒ‰é’®ã€‚é‡è·‘æˆåŠŸåè§¦å‘ä¸€æ¬¡å±€éƒ¨å½’å¹¶ä¸ UI åˆ·æ–°ã€‚
â€¢	å¹‚ç­‰ï¼šåŒä¸€ job_id + chunk_id + slides hash çš„é‡è·‘å¯è¦†ç›–æ—§ç»“æœï¼›ä¿ç•™å®¡è®¡æ—¥å¿—ã€‚
â€¢	å‚æ•°ï¼štemperature=0ï¼Œtop_p=1ï¼Œseed å¯é…ï¼›è¶…æ—¶ï¼ˆå¦‚ 60sï¼‰å¯é…ã€‚
________________________________________
8. è¿›åº¦æ˜¾ç¤ºï¼ˆå‰ç«¯ï¼‰
çŠ¶æ€æµï¼š
â€¢	è§£æ PPT â†’ å‘å‡º Prompt â†’ AI æ€è€ƒä¸­ â†’ æ•´ç†ç»“æœ
æ•°å€¼é€»è¾‘ï¼š
â€¢	å‘å‡º Promptè¿›åº¦ = chunks_sent / chunks_total
â€¢	AI æ€è€ƒä¸­è¿›åº¦ = chunks_completed / chunks_sent
â€¢	æ•´ç†ç»“æœä¸ºæœ€åå›ºå®š 10% è‡³ 100% çš„è¿‡æ¸¡ï¼ˆå¯æŒ‰é¡¹è®¡æ—¶å¹³æ»‘ï¼‰ã€‚
UI å…ƒç´ ï¼š
â€¢	æ€»ä½“è¿›åº¦æ¡ + åˆ†æ®µçŠ¶æ€æ ‡ç­¾
â€¢	å—çº§åˆ—è¡¨ï¼ˆchunk_idã€é¡µèŒƒå›´ã€çŠ¶æ€ã€é‡è·‘æŒ‰é’®ã€é”™è¯¯ä¿¡æ¯ï¼‰
â€¢	ç»“æœè¡¨æ ¼ï¼šå¯ç­›é€‰ï¼ˆä»…æ˜¾ç¤ºæœ‰é—®é¢˜çš„é¡µ/ä»…é€»è¾‘é—®é¢˜ç­‰ï¼‰
________________________________________
9. æ¥å£è®¾è®¡ï¼ˆç¤ºä¾‹ï¼‰
9.1 åç«¯ REST
â€¢	POST /zd/jobsï¼ˆä¸Šä¼ ï¼‰â†’ { job_id }
â€¢	GET /zd/jobs/{job_id}ï¼ˆæŸ¥è¯¢è¿›åº¦ï¼‰â†’ è§ 3.5
â€¢	POST /zd/jobs/{job_id}/runï¼ˆå¼€å§‹è§£æ+æ‰§è¡Œï¼Œå«æ¨¡å¼å‚æ•° mode=fast|preciseï¼‰
â€¢	POST /zd/jobs/{job_id}/chunks/{chunk_id}/retry
â€¢	GET /zd/jobs/{job_id}/result?format=markdown|json|csv|xlsx
9.2 é”™è¯¯ç ï¼ˆç¤ºä¾‹ï¼‰
â€¢	400 PPT_UNSUPPORTEDï¼ˆç©ºæ–‡ä»¶/æ ¼å¼é”™è¯¯ï¼‰
â€¢	413 FILE_TOO_LARGE
â€¢	429 RATE_LIMITED
â€¢	500 LLM_ERROR
â€¢	504 LLM_TIMEOUT
________________________________________
10. å…³é”®å®ç°ç»†èŠ‚ä¸ä¼ªä»£ç 
10.1 è§£æPPT
#!/usr/bin/env python3
"""
PowerPoint Text Extractor (CLI Edition)
---------------------------------------
 
â€¢ Prompts for:
    1) PowerPoint (.pptx) file path
    2) Desired output format (json / txt)
    3) Output file path
 
â€¢ Extracts slide-number-labeled text (titles, body text, tables, chart titles,
  speaker notes, etc.) using python-pptx.
 
â€¢ Saves either:
    â€¢ Structured JSON  â€“ best for downstream processing
    â€¢ Nicely formatted TXT â€“ easy for manual scanning or lightweight AI tools
"""
 
import json
import os
import sys
from pathlib import Path
 
try:
    from pptx import Presentation
    from pptx.enum.shapes import MSO_SHAPE_TYPE
    from pptx.enum.shapes import PP_PLACEHOLDER
except ImportError:
    sys.exit("âŒ  python-pptx is not installed.  Run:  pip install python-pptx")
 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Extraction helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_text_recursive(shape):
    """Recursively pull out text from a shape (handling groups, tables, charts)."""
    chunks = []
    sid = f"Shape ID {shape.shape_id}"
 
    # 1) Plain text frames -----------------------------------------------------
    if shape.has_text_frame and shape.text_frame.text.strip():
        text = shape.text_frame.text.strip()
        type_hint = "Body"
        if shape.is_placeholder:
            ph = shape.placeholder_format
            if ph.type in {
                PP_PLACEHOLDER.TITLE,
                PP_PLACEHOLDER.CENTER_TITLE,
                PP_PLACEHOLDER.SUBTITLE,
                PP_PLACEHOLDER.VERTICAL_TITLE,
            }:
                type_hint = "Title/Subtitle"
            elif ph.type == PP_PLACEHOLDER.BODY:
                type_hint = "Body Placeholder"
            elif ph.type == PP_PLACEHOLDER.OBJECT and "Title" in shape.name:
                type_hint = "Object Title"
 
        chunks.append({"id": sid, "type": type_hint, "text": text})
 
    # 2) Table cells -----------------------------------------------------------
    elif shape.has_table:
        tbl_txt = []
        for r, row in enumerate(shape.table.rows):
            for c, cell in enumerate(row.cells):
                cell_txt = cell.text_frame.text.strip()
                if cell_txt:
                    tbl_txt.append(f"Row {r+1}, Col {c+1}: {cell_txt}")
        if tbl_txt:
            chunks.append({"id": sid, "type": "Table", "text": "\\n".join(tbl_txt)})
 
    # 3) Grouped shapes --------------------------------------------------------
    elif shape.shape_type == MSO_SHAPE_TYPE.GROUP:
        for s in shape.shapes:
            chunks.extend(extract_text_recursive(s))
 
    # 4) Chart title (limited) -------------------------------------------------
    elif shape.has_chart:
        ch = shape.chart
        if ch.has_title and ch.chart_title.text_frame.text.strip():
            chunks.append(
                {
                    "id": sid,
                    "type": "Chart Info",
                    "text": f"Chart Title: {ch.chart_title.text_frame.text.strip()}",
                }
            )
 
    return chunks
 
def extract_powerpoint_text(pptx_path):
    """Return list[dict] â€“ one entry per slide â€“ or None on error."""
    if not Path(pptx_path).exists():
        print(f"âŒ  File not found: {pptx_path}")
        return None
 
    try:
        prs = Presentation(pptx_path)
    except Exception as exc:
        print(f"âŒ  Could not open presentation: {exc}")
        return None
 
    slides_data = []
    for idx, slide in enumerate(prs.slides, start=1):
        slide_info = {"slide_number": idx, "elements": [], "notes": None}
 
        for shp in slide.shapes:
            slide_info["elements"].extend(extract_text_recursive(shp))
 
        if slide.has_notes_slide:
            notes_tf = slide.notes_slide.notes_text_frame
            if notes_tf and notes_tf.text.strip():
                slide_info["notes"] = notes_tf.text.strip()
 
        if slide_info["elements"] or slide_info["notes"]:
            slides_data.append(slide_info)
 
    return slides_data
 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Simple CLI prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def prompt_path(prompt_msg, must_exist=False, default=None):
    while True:
        path_str = input(f"{prompt_msg}{' ['+default+']' if default else ''}: ").strip()
        if not path_str and default:
            path_str = default
        if not path_str:
            print("  â†³ Please enter a path.")
            continue
        p = Path(path_str).expanduser()
        if must_exist and not p.exists():
            print("  â†³ Path does not exist; try again.")
            continue
        return p
 
def prompt_format():
    while True:
        fmt = input("Choose output format (json/txt): ").strip().lower()
        if fmt in {"json", "txt"}:
            return fmt
        print("  â†³ Enter 'json' or 'txt'.")
 
def main():
    print("\\nğŸ“  PowerPoint Text Extractor (CLI)\\n" + "â”€" * 40)
 
    pptx_path = prompt_path("Enter .pptx file path", must_exist=True)
 
    out_format = prompt_format()
 
    default_out = (
        pptx_path.with_suffix(".json")
        if out_format == "json"
        else pptx_path.with_suffix(".txt")
    )
    out_path = prompt_output_path(default_out)
 
    # -------------------------------------------------------------------------
    print("\\nğŸ”  Extracting text â€¦")
    data = extract_powerpoint_text(pptx_path)
    if not data:
        sys.exit("âŒ  No extractable text found or an error occurred.")
 
    # -------------------------------------------------------------------------
    try:
        if out_format == "json":
            with open(out_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4, ensure_ascii=False)
        else:  # txt
            with open(out_path, "w", encoding="utf-8") as f:
                for slide in data:
                    f.write(f"--- Slide {slide['slide_number']} ---\\n\\n")
 
                    titles = [
                        e["text"]
                        for e in slide["elements"]
                        if e["type"] == "Title/Subtitle"
                    ]
                    if titles:
                        f.write("Tagline/Title(s):\\n")
                        for t in titles:
                            f.write(f"- {t}\\n")
                        f.write("\\n")
 
                    f.write("Body/Other Elements:\\n")
                    body_found = False
                    for e in slide["elements"]:
                        if e["type"] != "Title/Subtitle":
                            body_found = True
                            lines = e["text"].splitlines()
                            first = lines[0]
                            rest = "\\n  ".join(lines[1:]) if len(lines) > 1 else ""
                            f.write(f"- [{e['type']} / {e['id']}] {first}")
                            if rest:
                                f.write(f"\\n  {rest}")
                            f.write("\\n")
                    if not body_found:
                        f.write("(No other text elements found on this slide)\\n")
 
                    if slide["notes"]:
                        f.write("\\nSpeaker Notes:\\n")
                        f.write(slide["notes"] + "\\n")
                    else:
                        f.write("\\nSpeaker Notes: (None)\\n")
 
                    f.write("\\n" + "=" * 20 + "\\n\\n")
 
        print(f"âœ…  Saved output to: {out_path.resolve()}")
    except Exception as exc:
        sys.exit(f"âŒ  Failed to write output: {exc}")
 
def prompt_output_path(default_path):
    """
    Ask for an output path. If the user types a directory, append the default
    file name. Also auto create the directory tree if it doesnâ€™t exist.
    """
    while True:
        raw = input(f"Enter output file path [{default_path}]: ").strip()
        raw = raw or str(default_path)
        p = Path(raw).expanduser()
 
        # If they gave a directory, append the default file name
        if p.is_dir() or (not p.suffix and p.exists()):
            p = p / default_path.name
 
        try:
            p.parent.mkdir(parents=True, exist_ok=True)
            return p
        except Exception as e:
            print(f"  â†³ Canâ€™t use that location: {e}")
 
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\\nâ¹ï¸  Aborted by user.")
________________________________________
________________________________________
11. æ€§èƒ½ä¸è´¨é‡æŒ‡æ ‡ï¼ˆå»ºè®®ï¼‰
â€¢	è§£æè€—æ—¶ï¼š< 5s/100 é¡µï¼ˆçº¯æ–‡æœ¬ï¼‰
â€¢	LLM æˆåŠŸç‡ï¼š> 98%ï¼ˆä»¥å—ä¸ºå•ä½ï¼‰
â€¢	æ•´ä½“ TTRï¼ˆ100 é¡µï¼Œå¿«é€Ÿæ¨¡å¼ï¼Œ5 å¹¶å‘ï¼‰ï¼šå¯ä½œä¸ºåŸºå‡†æµ‹é‡å¹¶ä¼˜åŒ–
â€¢	æ­£ç¡®æ€§æŠ½æ£€ï¼šæŠ½æ ·é¡µäººå·¥æ¯”å¯¹ï¼ˆæ‹¼å†™ã€è¯­æ³•ã€é€»è¾‘ä¸‰ç±»å„å–æ ·ï¼‰ã€‚
________________________________________
12. å‰ç«¯äº¤äº’è¦ç‚¹
â€¢	ä¸Šä¼ åç«‹å³æ˜¾ç¤ºé¡µé¢ç»Ÿè®¡ï¼ˆæ€»é¡µæ•°/è¯æ•°ä¼°è®¡/å»ºè®®æ¨¡å¼ï¼‰ã€‚
â€¢	æ¨¡å¼åˆ‡æ¢æç¤ºï¼š 
o	å¿«é€Ÿï¼šååä¼˜å…ˆã€æˆæœ¬æ›´ä½
o	ä»”ç»†ï¼šæŸ¥é”™æ›´æ•æ„Ÿã€è·¨é¡µé€»è¾‘æ›´ç¨³
â€¢	ç»“æœé¡µï¼š 
o	è¡¨æ ¼è¡Œ = é¡µï¼›ä¸‰åˆ—é—®é¢˜ï¼›ç©ºç”¨ â€”ï¼›å¯å±•å¼€æŸ¥çœ‹åŸå§‹ tagline/body_other é¢„è§ˆ
o	å¤±è´¥å—é†’ç›®æ ‡è¯† + â€œé‡è·‘â€
13. LLM è®¾ç½®
â€¢	ä½¿ç”¨chatgptä½œä¸ºLLMæ¨¡å‹ï¼Œ å…è®¸ç”¨æˆ·é€‰æ‹©æ¨¡å‹ï¼ŒåŒ…æ‹¬gpt-5ï¼Œgpt-5-thinkingï¼Œgpt-4.5ï¼Œgpt-5-pro
â€¢	æ¨¡å‹è®¾ç½®å‚è€ƒenvironmentä¸­çš„base urlå’Œapi key
 
